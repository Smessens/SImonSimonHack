{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon 2: Fuel consumption model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of fuel a vehicle uses to travel a distance is defined as Fuel Consumption. Fuel Consumption is a significant factor to be optimized for enterprises and professionals of transportation to maximize profits and achieve better functionality of the enterprise. Predicting fuel consumption using only a few features will help managers to choose routes and times of transportation that will guide to an increased fuel economy. The raw dataset is available on Kaggle:\n",
    "\n",
    "https://www.kaggle.com/yiorgos1973/fuelconsumption\n",
    "\n",
    "The database (file fuelConsumptionhack2.csv) contains 4491 records with the following information a fleet of light trucks: \n",
    "\n",
    "Payload:  Describes the loaded cargo.\n",
    "\n",
    "Reliability: Probability of this route to be on time according to historical data.\n",
    "\n",
    "Season: Describes the weather condition. 0 is good weather and 1 is bad weather\n",
    "\n",
    "Net: This is a discrete quantitative variable that describes the quality of the roadnet. 1 is bad quality, 2 is mediocre and 3 is good quality\n",
    "\n",
    "LoadValue: This is the value of the cargo of the light truck\n",
    "\n",
    "TransmissionType: Truck can have automatic or manual transmission.\n",
    "\n",
    "Fuel: The dependent variable. It is describing the fuel consumption of a truck when doing this route (l/100km).\n",
    "\n",
    "Your aim is to understand how the fuel consumption can be explained by other recorded features. You will use pandas, numpy to read the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"fuelConsumptionhack2.csv\",sep=\";\")\n",
    "Pay = data[\"Payload\"].values\n",
    "Rel = data[\"Reliability\"].values\n",
    "Sea = data[\"Season\"].values\n",
    "Net = data[\"Net\"].values\n",
    "LV = data[\"LoadValue\"].values\n",
    "TT = data[\"TransmissionType\"].values\n",
    "Fuel = data[\"Fuel\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing\n",
    "1) We start our analysis by checking that the average consumption is above 15 l/100km. To do this, perform a one-sided test for a confidence level of 95% (alpha=5%). Write clearly the tested assumptions and Report the statistics, critical value and the p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 16.508159869000547 , Variance: 3.4078219088079567\n",
      "H0 : mu(Fuel) = 15\n",
      "H1 : mu(Fuel) > 15\n",
      "\n",
      "T(X):  54.76172806719549\n",
      "Critical value:  1.6451929157669274\n",
      "We see that T(X) is above the critical value, hence we reject H0\n",
      "p-value: 0.0 < alpha (5%) => We confirm the rejection of H0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "\n",
    "X    = Fuel[:]\n",
    "n    = len(X)\n",
    "\n",
    "# we get the statistics\n",
    "Stat=sc.describe(X)\n",
    "print(\"Mean:\",Stat.mean,\", Variance:\", Stat.variance)\n",
    "\n",
    "print(\"H0 : mu(Fuel) = 15\\nH1 : mu(Fuel) > 15\\n\")\n",
    "\n",
    "# we calculate T(X)\n",
    "Tx= (Stat.mean-15)/np.sqrt(Stat.variance/n)\n",
    "\n",
    "# we compare it to the percentiles of a t distribution\n",
    "alpha = 0.05\n",
    "t_u   = sc.t.ppf(q=1-alpha,df=n-1)\n",
    "print(\"T(X): \",Tx)\n",
    "print(\"Critical value: \",t_u)\n",
    "print(\"We see that T(X) is above the critical value, hence we reject H0\")\n",
    "\n",
    "#The p-value is\n",
    "pval = 1-sc.t.cdf(np.abs(Tx),df=n-1)\n",
    "print(\"p-value:\",pval, \"< alpha (5%) => We confirm the rejection of H0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) We continue with an analysis of the transmission type on the average fuel consumption. Under the assumption of equal variances, test if the average consumption of automatic vehicles is the same as the one with a manual transmission (use a two-sided test and a confidence level of 95%, i.e. \\alpha=5% ). Report the statistics, critical values and the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic: Mean: 16.42050764687532 , Variance: 3.2239692302077048\n",
      "Manual:    Mean: 16.555655702471977 , Variance: 3.5021653593719293\n",
      "H0 : mu(Auto)-mu(Manual) = 0\n",
      "H1 : mu(Auto)-mu(Manual) is different from 0\n",
      "\n",
      "Assumption : variance is the same for manual and automatic and equal to 3.4043973451386083 \n",
      "\n",
      "T(X1,X2): -2.3439983931797244\n",
      "Critical values: [-1.9599639845400545, 1.959963984540054]\n",
      "We see that T(X1,X2) is outside of the critical values interval, hence we reject H0\n",
      "p-value: 0.019078253589527083 < alpha (5%) => We confirm the rejection of H0\n"
     ]
    }
   ],
   "source": [
    "#dividing the set in two subsets based on the transmition\n",
    "TT_auto=[Fuel[i] for i in range(len(Fuel)) if TT[i]=='automatic']\n",
    "TT_man=[Fuel[i] for i in range(len(Fuel)) if TT[i]=='manual']\n",
    "n1=len(TT_auto)\n",
    "n2=len(TT_man)\n",
    "\n",
    "#we get the statistics\n",
    "X1=sc.describe(TT_auto)\n",
    "X2=sc.describe(TT_man)\n",
    "print('Automatic:',\"Mean:\",X1.mean,\", Variance:\",X1.variance )\n",
    "print('Manual:',\"   Mean:\",X2.mean,\", Variance:\", X2.variance )\n",
    "\n",
    "print(\"H0 : mu(Auto)-mu(Manual) = 0\\nH1 : mu(Auto)-mu(Manual) is different from 0\\n\")\n",
    "\n",
    "#We find the pool variance\n",
    "Var_pool=X1.variance*n1/(n1+n2)+X2.variance*n2/(n1+n2)\n",
    "print(\"Assumption : variance is the same for manual and automatic and equal to\",Var_pool,\"\\n\")\n",
    "\n",
    "#we find the value of T(X1,X2)\n",
    "alpha=0.05\n",
    "Txy=(X1.mean-X2.mean)/np.sqrt(Var_pool*(1/n1+1/n2))\n",
    "print(\"T(X1,X2):\",Txy)\n",
    "t_l = sc.norm.ppf(alpha/2)\n",
    "t_u = sc.norm.ppf(1-alpha/2)\n",
    "print(\"Critical values:\",[t_l,t_u])\n",
    "\n",
    "print(\"We see that T(X1,X2) is outside of the critical values interval, hence we reject H0\")\n",
    "\n",
    "#The p-value is\n",
    "pval = 2*(1-sc.norm.cdf(np.abs(Txy)))\n",
    "print(\"p-value:\",pval, \"< alpha (5%) => We confirm the rejection of H0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) The test in question 2 is performed under the assumption of equal variances. Test this assumption with a confidence level of 95% (two-sided test, \\alpha=5%). Report the values of statistics and the critical values (p-value not requested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Stat_auto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b4119b8150ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Automatic:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Variance:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStat_auto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Manual:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Variance:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStat_man\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"H0 : sigma(Auto) = sigma(Manual)\\nH1 : sigma(Auto) is different from sigma(Manual)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#we find the value of T(X1,X2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Stat_auto' is not defined"
     ]
    }
   ],
   "source": [
    "print('Automatic:',\"Variance:\", Stat_auto.variance )\n",
    "print('Manual:',\"Variance:\", Stat_man.variance )\n",
    "print(\"H0 : sigma(Auto) = sigma(Manual)\\nH1 : sigma(Auto) is different from sigma(Manual)\\n\")\n",
    "\n",
    "#we find the value of T(X1,X2)\n",
    "alpha=0.05\n",
    "Txy=Stat_auto.variance/Stat_man.variance\n",
    "print(\"T(X1,X2):\",Txy)\n",
    "t_l = sc.f.ppf(alpha/2,dfn=n1-1,dfd=n2-1)\n",
    "t_u = sc.f.ppf(1-alpha/2,dfn=n1-1,dfd=n2-1)\n",
    "print(\"Critical values:\",[t_l,t_u])\n",
    "\n",
    "print(\"We see that T(X1,X2) is inside of the critical values interval, hence we do not reject H0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  4) Under the assumption of equal variances, test if the average consumption is the same with bad or good weather conditions (use a two-sided test and a confidence level of 95%, i.e. \\alpha=5% ). Report  the statistics, critical values and the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good weather: Mean: 16.053005795731895 , Variance: 2.3596204431511048\n",
      "Bad weather:  Mean: 19.165650013686328 , Variance: 1.256410059476164\n",
      "H0 : mu(Good W.)-mu(Bad W.) = 0\n",
      "H1 : mu(Good W.)-mu(Bad W.) is different from 0\n",
      "\n",
      "Assumption : variance is the same for good and bad weather and equal to  2.198300785444798 \n",
      "\n",
      "T(X1,X2): -49.72098227948306\n",
      "Critical values: [-1.9599639845400545, 1.959963984540054]\n",
      "We see that T(X1,X2) is outside of the critical values interval, hence we reject H0\n",
      "p-value: 0.0 < alpha (5%) => We confirm the rejection of H0\n"
     ]
    }
   ],
   "source": [
    "#dividing the set in two subsets based on the weather\n",
    "Good_W=[Fuel[i] for i in range(len(Fuel)) if Sea[i]==0]\n",
    "Bad_W=[Fuel[i] for i in range(len(Fuel)) if Sea[i]==1]\n",
    "n1=len(Good_W)\n",
    "n2=len(Bad_W)\n",
    "\n",
    "#we get the statistics\n",
    "X1=sc.describe(Good_W)\n",
    "X2=sc.describe(Bad_W)\n",
    "print('Good weather:',\"Mean:\",X1.mean,\", Variance:\",X1.variance )\n",
    "print('Bad weather:',\" Mean:\",X2.mean,\", Variance:\", X2.variance )\n",
    "\n",
    "print(\"H0 : mu(Good W.)-mu(Bad W.) = 0\\nH1 : mu(Good W.)-mu(Bad W.) is different from 0\\n\")\n",
    "\n",
    "#We find the pool variance\n",
    "Var_pool=X1.variance*n1/(n1+n2)+X2.variance*n2/(n1+n2)\n",
    "print(\"Assumption : variance is the same for good and bad weather and equal to \",Var_pool,\"\\n\")\n",
    "\n",
    "#we find the value of T(X1,X2)\n",
    "alpha=0.05\n",
    "Txy=(X1.mean-X2.mean)/np.sqrt(Var_pool*(1/n1+1/n2))\n",
    "print(\"T(X1,X2):\",Txy)\n",
    "t_l = sc.norm.ppf(alpha/2)\n",
    "t_u = sc.norm.ppf(1-alpha/2)\n",
    "print(\"Critical values:\",[t_l,t_u])\n",
    "\n",
    "print(\"We see that T(X1,X2) is outside of the critical values interval, hence we reject H0\")\n",
    "\n",
    "#The p-value is\n",
    "pval = 2*(1-sc.norm.cdf(np.abs(Txy)))\n",
    "print(\"p-value:\",pval, \"< alpha (5%) => We confirm the rejection of H0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "5) The next step consists to perform a linear regression of the variable “Fuel consumption” on all other explanatory variables.\n",
    "i.\tReport the F statistics and interpret it\n",
    "ii.\tWhat does measure the R2?\n",
    "iii.\tAnalyze the t-statistics and p-values of coefficients of regression. Are all coefficients significant at 5%? Use the library statsmodels.api. The function OLS accepts pandas dataframe (use .drop() to remove columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Pay\n",
      "Beta1 = 1.5851\n",
      "Beta0 = 257.8857\n",
      "R^2 = 0.0562\n",
      "F^* = 267.4013\n",
      "Fisher = 3.8435\n",
      "T^* of b0 = 160.1559\n",
      "T^* of b1 = 16.3524\n",
      "t 97.5% = 1.9605\n",
      "Interval confidence of beta0 = [254.7288 , 261.0425]\n",
      "Interval confidence of beta1 = [1.3951 , 1.7752]\n",
      "Pvalue of beta0 = 0.0000\n",
      "Pvalue of beta1 = 0.0000\n",
      "The coefficients are not significants because R-squared is low\n",
      "\n",
      "For Rel\n",
      "Beta1 = -2.9359\n",
      "Beta0 = 118.6504\n",
      "R^2 = 0.6611\n",
      "F^* = 8760.1602\n",
      "Fisher = 3.8435\n",
      "T^* of b0 = 227.7137\n",
      "T^* of b1 = -93.5957\n",
      "t 97.5% = 1.9605\n",
      "Interval confidence of beta0 = [117.6289 , 119.6719]\n",
      "Interval confidence of beta1 = [-2.9974 , -2.8744]\n",
      "Pvalue of beta0 = 0.0000\n",
      "Pvalue of beta1 = 0.0000\n",
      "\n",
      "For Sea\n",
      "Beta1 = 0.1141\n",
      "Beta0 = -1.7366\n",
      "R^2 = 0.3550\n",
      "F^* = 2471.9806\n",
      "Fisher = 3.8435\n",
      "T^* of b0 = -45.5737\n",
      "T^* of b1 = 49.7190\n",
      "t 97.5% = 1.9605\n",
      "Interval confidence of beta0 = [-1.8113 , -1.6619]\n",
      "Interval confidence of beta1 = [0.1096 , 0.1186]\n",
      "Pvalue of beta0 = 0.0000\n",
      "Pvalue of beta1 = 0.0000\n",
      "The coefficients are not significants because R-squared is low\n",
      "\n",
      "For Net\n",
      "Beta1 = -0.2583\n",
      "Beta0 = 6.6442\n",
      "R^2 = 0.7323\n",
      "F^* = 12284.9515\n",
      "Fisher = 3.8435\n",
      "T^* of b0 = 171.6358\n",
      "T^* of b1 = -110.8375\n",
      "t 97.5% = 1.9605\n",
      "Interval confidence of beta0 = [6.5683 , 6.7201]\n",
      "Interval confidence of beta1 = [-0.2629 , -0.2537]\n",
      "Pvalue of beta0 = 0.0000\n",
      "Pvalue of beta1 = 0.0000\n",
      "\n",
      "For LV\n",
      "Beta1 = -77.7965\n",
      "Beta0 = 2138.6594\n",
      "R^2 = 0.3315\n",
      "F^* = 2227.0919\n",
      "Fisher = 3.8435\n",
      "T^* of b0 = 78.1005\n",
      "T^* of b1 = -47.1921\n",
      "t 97.5% = 1.9605\n",
      "Interval confidence of beta0 = [2084.9744 , 2192.3444]\n",
      "Interval confidence of beta1 = [-81.0284 , -74.5646]\n",
      "Pvalue of beta0 = 0.0000\n",
      "Pvalue of beta1 = 0.0000\n",
      "The coefficients are not significants because R-squared is low\n",
      "\n",
      "For TT\n",
      "Beta1 = 0.0090\n",
      "Beta0 = 0.4993\n",
      "R^2 = 0.0012\n",
      "F^* = 5.4943\n",
      "Fisher = 3.8435\n",
      "T^* of b0 = 7.7929\n",
      "T^* of b1 = 2.3440\n",
      "t 97.5% = 1.9605\n",
      "Interval confidence of beta0 = [0.3737 , 0.6249]\n",
      "Interval confidence of beta1 = [0.0015 , 0.0166]\n",
      "Pvalue of beta0 = 0.0000\n",
      "Pvalue of beta1 = 0.0096\n",
      "The coefficients are not significants because R-squared is low\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sc\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "TT2=TT\n",
    "for i in range(len(TT)):\n",
    "    if(TT[i]==\"automatic\"):\n",
    "        TT2[i]=0\n",
    "    else:\n",
    "       TT2[i] =1\n",
    "    \n",
    "\n",
    "liste = [Pay,Rel,Sea,Net,LV,TT]\n",
    "liste2 =[\"Pay\",\"Rel\",\"Sea\",\"Net\",\"LV\",\"TT\"]\n",
    "for i in range(len(liste2)):\n",
    "    x = Fuel\n",
    "    y = liste[i]\n",
    "    xbar = sum(x)/len(x)\n",
    "    ybar = sum(y)/len(y)\n",
    "    Sxx = 0\n",
    "    Sxy = 0\n",
    "    xsquaredbar =0\n",
    "    for j in range(len(x)):\n",
    "        Sxx += (x[j]-xbar)*(x[j]-xbar)\n",
    "        Sxy += (x[j]-xbar)*(y[j]-ybar)\n",
    "        xsquaredbar += x[j]*x[j]\n",
    "    xsquaredbar /= len(x)\n",
    "    beta1hat = Sxy/Sxx\n",
    "    beta0hat = ybar - beta1hat * xbar\n",
    "    yhat = beta1hat * x + beta0hat\n",
    "    SST = sum((y-ybar)*(y-ybar))\n",
    "    SSR = sum((yhat-ybar)*(yhat-ybar))\n",
    "    SSE = sum((y-yhat)*(y-yhat))\n",
    "    Rsquared = SSR/SST\n",
    "    sigmahat = np.sqrt(SSE/(len(x)-1-1))\n",
    "    sigmahatb0 = np.sqrt(sigmahat* sigmahat * xsquaredbar /Sxx)\n",
    "    sigmahatb1 = np.sqrt(sigmahat*sigmahat /Sxx)\n",
    "    c00= xsquaredbar/Sxx\n",
    "    c11 = 1/Sxx\n",
    "    Fstar= SSR/(SSE/(len(x)-1-1))\n",
    "    F = sc.f.ppf(0.95,1,len(x)-1-1)\n",
    "    t = sc.t.ppf(0.975,df=len(x)-1-1)\n",
    "    Tstarb0 = beta0hat/(sigmahat*np.sqrt(c00))\n",
    "    Tstarb1 = beta1hat/(sigmahat*np.sqrt(c11))\n",
    "    \n",
    "    ICb0 = [beta0hat -t*sigmahat*np.sqrt(c00),beta0hat +t*sigmahat*np.sqrt(c00)]\n",
    "    ICb1 = [beta1hat -t*sigmahat*np.sqrt(c11),beta1hat +t*sigmahat*np.sqrt(c11)]\n",
    "    \n",
    "    pValueb0 = sc.t.sf(abs(Tstarb0),len(x)-1-1)\n",
    "    pValueb1 = sc.t.sf(abs(Tstarb1),len(x)-1-1)\n",
    "    \n",
    "    \n",
    "    print(\"For \" + liste2[i])\n",
    "    print(\"Beta1 = \"+\"%.4f\"% beta1hat)\n",
    "    print(\"Beta0 = \" + \"%.4f\"% beta0hat)\n",
    "    print(\"R^2 = \" + \"%.4f\"% Rsquared)\n",
    "    print(\"F^* = \"+\"%.4f\"% Fstar)\n",
    "    print(\"Fisher = \"+ \"%.4f\"% F)\n",
    "    print(\"T^* of b0 = \" \"%.4f\"% Tstarb0)\n",
    "    print(\"T^* of b1 = \" \"%.4f\"% Tstarb1)\n",
    "    print(\"t 97.5% = \"+\"%.4f\"%t)\n",
    "    print(\"Interval confidence of beta0 = [\" +\"%.4f\"% ICb0[0] + \" , \" + \"%.4f\"% ICb0[1]+\"]\")\n",
    "    print(\"Interval confidence of beta1 = [\" +\"%.4f\"% ICb1[0] + \" , \" + \"%.4f\"% ICb1[1]+\"]\")\n",
    "    print(\"Pvalue of beta0 = \"+ \"%.4f\"% pValueb0)\n",
    "    print(\"Pvalue of beta1 = \"+ \"%.4f\"% pValueb1)\n",
    "    if(Rsquared <0.5):\n",
    "        print(\"The coefficients are not significants because R-squared is low\")\n",
    "    if(pValueb0 >0.05 or pValueb1 > 0.05):\n",
    "        if(pValueb1 > 0.05):\n",
    "            print(\"The coefficient of b1 is not significant because p-value is hiegher than 5%\")\n",
    "        else:\n",
    "            print(\"The coefficient of b0 is not significant because p-value is hiegher than 5%\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F statistic can be interpreted as the explained variance on unexplained variance. It means that when the F statistic is too small then the linearity between X et Y must be rejected.//\n",
    "R squared, the coefficient of determination, measures the quality of the linear regression. Its value is between 0 and 1. The closer to 1, the better is the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Remove non-significant coefficients and run again the regression. Compare the Log-likelihood, AIC and BIC (the AIC and BIC are not explained in the course, search on internet for explanations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.661\n",
      "Model:                            OLS   Adj. R-squared:                  0.661\n",
      "Method:                 Least Squares   F-statistic:                     8760.\n",
      "Date:                Thu, 05 Nov 2020   Prob (F-statistic):               0.00\n",
      "Time:                        15:06:46   Log-Likelihood:                -12467.\n",
      "No. Observations:                4493   AIC:                         2.494e+04\n",
      "Df Residuals:                    4491   BIC:                         2.495e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        118.6504      0.521    227.714      0.000     117.629     119.672\n",
      "x1            -2.9359      0.031    -93.596      0.000      -2.997      -2.874\n",
      "==============================================================================\n",
      "Omnibus:                       16.625   Durbin-Watson:                   1.786\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               12.988\n",
      "Skew:                          -0.029   Prob(JB):                      0.00151\n",
      "Kurtosis:                       2.743   Cond. No.                         150.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.732\n",
      "Model:                            OLS   Adj. R-squared:                  0.732\n",
      "Method:                 Least Squares   F-statistic:                 1.228e+04\n",
      "Date:                Thu, 05 Nov 2020   Prob (F-statistic):               0.00\n",
      "Time:                        15:06:46   Log-Likelihood:                -786.66\n",
      "No. Observations:                4493   AIC:                             1577.\n",
      "Df Residuals:                    4491   BIC:                             1590.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          6.6442      0.039    171.636      0.000       6.568       6.720\n",
      "x1            -0.2583      0.002   -110.838      0.000      -0.263      -0.254\n",
      "==============================================================================\n",
      "Omnibus:                     3421.459   Durbin-Watson:                   1.768\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              264.678\n",
      "Skew:                          -0.029   Prob(JB):                     3.36e-58\n",
      "Kurtosis:                       1.812   Cond. No.                         150.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "liste3 = [Rel,Net]\n",
    "\n",
    "Xm = sm.add_constant(Fuel)\n",
    "for elem in liste3 :\n",
    "    # we fit by least square minimization the model\n",
    "    results = sm.OLS(elem,Xm).fit()\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AIC is an estimator of out-of-sample prediction error. It is related to the quality of statistical models for a given set of data. A good model is the one that has minimum AIC among all the other models thus a lower AIC value indicates a better fit. The BI is a criterion for model selection among a finite set of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) We have treated categorical variables (Season, net, TransmissionType) as continuous explanatory variables. For binary variables as Season or TransmissionType (coded as 0-1), the coefficient of regression (\\beta) represents the marginal impact of the Season or TransmissionType on fuel consumption. For categorical variables with more than 2 instances, like “net”, the \\beta is not clearly interpretable. Imagine that we code net as : 1=mediocre, 2=good, 3=bad, we would obtain a totally different value for the beta because the coding of road quality has no natural order. In practice, non-binary categorical variable cannot by entered in the regression equation just as they are. We must recode them into several binary variables. For example, the variable NET is removed and split into 2 binary variables BAD and MEDIOCRE as follows:\n",
    "\n",
    "If net=1 (bad quality): we replace it by BAD=1 , MEDIOCRE=0\n",
    "If net=1 (mediocre quality): we replace it by BAD=0 , MEDIOCRE=1\n",
    "If net=1 (good quality): we replace it by BAD=0 , MEDIOCRE=0\n",
    "\n",
    "We do not add a binary variable for roads of good quality because it generates identifiability problems with the intercept beta_0. In general, a categorical variable with n instances in recoded as n-1 binary variables.\n",
    "\n",
    "Recode the variable NET into two binary variables and rerun the regression.  Compare the Log-likelihood , AIC and BIC of this model with previous ones. (use drop() and insert() to remove/add columns to a dataframe).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
